{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DB0vv4pBcWu9"
   },
   "source": [
    "# Q3 Using Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GalZFbfhcWvA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r8CbpTPx9rKA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zzheng309\n"
     ]
    }
   ],
   "source": [
    "# Change to your GA Tech ID\n",
    "ga_id = 'zzheng309'\n",
    "# Requires a print() statement do not modify below print statement\n",
    "print(ga_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Z1gV3UlcWvD"
   },
   "source": [
    "# Q3.1 Data Import and Cleansing Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9VS44b2kcWvE"
   },
   "outputs": [],
   "source": [
    "# XXX\n",
    "# TODO: Read in all the data. Replace the 'xxx' with the path to the data set. We've started this for you. \n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "data = pd.read_csv('pulsar_stars.csv')\n",
    "# -------------------------------\n",
    "\n",
    "# XXX\n",
    "# TODO: Separate out the x_data and y_data. We've started this for you.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "x_data = data.iloc[:,:-1]\n",
    "y_data = data.iloc[:,-1]\n",
    "# -------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xuEypbCqcWvG"
   },
   "outputs": [],
   "source": [
    "# XXX\n",
    "# TODO: Split 70% of the data into training and 30% into test sets. Call them x_train, x_test, y_train and y_test.\n",
    "# Use the train_test_split method in sklearn with the parameter 'shuffle' set to true and the 'random_state' \n",
    "# set to 614.\n",
    "# \n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, shuffle=True, random_state=614)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q09V5Ux5cWvI"
   },
   "source": [
    "# Q3.2 Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tnHXBF1UcWvJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Create a LinearRegression classifier and train it.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# \n",
    "reg = LinearRegression()\n",
    "reg.fit(x_train, y_train)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "McSbfk9WcWvL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9720625798212005\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy (on the training set) using the accuracy_score method.\n",
    "# Note: Round the output values greater than or equal to 0.5 to 1 and those less than 0.5 to 0. You can use any method that satisfies the requriements.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "y_train_pred = reg.predict(x_train)\n",
    "number_filter = y_train_pred >= 0.5\n",
    "y_train_pred_rounded = np.zeros(len(y_train_pred))\n",
    "y_train_pred_rounded[number_filter] = 1.0\n",
    "print(accuracy_score(y_train_pred_rounded, y_train))\n",
    "\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VgySbn7xcWvN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9696461824953445\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy (on the testing set) using the accuracy_score method.\n",
    "# Note: Round the output values greater than or equal to 0.5 to 1 and those less than 0.5 to 0. You can use any method that satisfies the requriements.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "y_test_pred = reg.predict(x_test)\n",
    "number_filter = y_test_pred >= 0.5\n",
    "y_test_pred_rounded = np.zeros(len(y_test_pred))\n",
    "y_test_pred_rounded[number_filter] = 1.0\n",
    "print(accuracy_score(y_test_pred_rounded, y_test))\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WbqnCyHAcWvP"
   },
   "source": [
    "# Q3.3 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dTtIFJW7cWvQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Andrew/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=614, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Create a RandomForestClassifier and train it.\n",
    "# Set 'random_state' to 614\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "\n",
    "rf = RandomForestClassifier(random_state=614)\n",
    "rf.fit(x_train, y_train)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IWeNJLzqcWvS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9968071519795658\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy on the training set using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "y_train_pred = rf.predict(x_train)\n",
    "print(accuracy_score(y_train_pred, y_train))\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wsMXeLyncWvU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9767225325884544\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy on the test set using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "y_test_pred = rf.predict(x_test)\n",
    "print(accuracy_score(y_test_pred, y_test))\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uEkwb0M3cWvW"
   },
   "source": [
    "## Q3.3.1 Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YmjevLlPcWvW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36631348 0.05096543 0.25857456 0.11768744 0.05862141 0.03806286\n",
      " 0.05627799 0.05349682]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Determine the feature importance as evaluated by the Random Forest Classifier.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "importances = rf.feature_importances_\n",
    "print(importances)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8XcRI7kUcWvY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 3 4 6 7 1 5]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Sort them in the descending order and print the feature numbers[0 to ...].\n",
    "#       Hint: There is a direct function available in sklearn to achieve this. Also checkout argsort() function in Python.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "\n",
    "sorted_index = np.argsort(importances)[::-1]\n",
    "print(sorted_index)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1AlCc_E3cWva"
   },
   "source": [
    "## Q3.3.2 Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y3fjpmWLcWvb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=614, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [4, 16, 256], 'max_depth': [2, 8, 16]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Tune the hyper-parameters 'n_estimators' and 'max_depth'.\n",
    "# 'n_estimators': [4, 16, 256]\n",
    "# 'max_depth': [2, 8, 16]\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "n_estimators = [4, 16, 256]\n",
    "max_depth = [2, 8, 16]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth}\n",
    "\n",
    "rf_random = GridSearchCV(estimator = rf,\n",
    "            param_grid = random_grid, \n",
    "            cv = 5)\n",
    "\n",
    "rf_random.fit(x_train,y_train)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y0OaHSCRcWvc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 16, 'n_estimators': 256}\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get the best params, using .best_params_\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "print(rf_random.best_params_)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eyXkkZr9cWve"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9794859514687101\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get the best score, using .best_score_.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "\n",
    "print(rf_random.best_score_)\n",
    "\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BNeOPWIpcWvg"
   },
   "source": [
    "# Q3.4 Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CN3Wkw7zcWvh"
   },
   "source": [
    "## Q3.4.1 Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9msZXyImcWvh"
   },
   "outputs": [],
   "source": [
    "# XXX\n",
    "# TODO: Pre-process the data to standardize it, otherwise the grid search will take much longer.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_std = scaler.transform(x_train)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pqz1htxM9rLO"
   },
   "source": [
    "## Q3.4.2 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g_nrOJdIcWvj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Create a SVC classifier and train it.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "\n",
    "svm = SVC()\n",
    "svm.fit(x_train_std, y_train)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U40EOPEecWvl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9802043422733078\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy on the training set using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "y_train_pred = svm.predict(x_train_std)\n",
    "print(accuracy_score(y_train_pred, y_train))\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x_jidMDvcWvm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9757914338919925\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy on the test set using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "\n",
    "x_test_std = scaler.transform(x_test)\n",
    "y_test_pred = svm.predict(x_test_std)\n",
    "print(accuracy_score(y_test_pred, y_test))\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "89N3JURqcWvp"
   },
   "source": [
    "## Q3.4.3 Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ufWB_j_-cWvq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'kernel': ('linear', 'rbf'), 'C': [0.01, 0.1, 1.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Tune the hyper-parameters 'C' and 'kernel' (use rbf and linear).\n",
    "# 'kernel':('linear', 'rbf') \n",
    "# 'C':[0.01, 0.1, 1.0]\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[0.01,0.1,1.0]}\n",
    "svm1=SVC(gamma='auto')\n",
    "clf1 = GridSearchCV(svm1, parameters, cv=10,n_jobs=-1, return_train_score=True)\n",
    "clf1.fit(x_train_std, y_train)\n",
    "\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dYsFkceBcWvu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9794859514687101\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get the best score, using .best_score_.\n",
    "# Note: Set n_jobs=-1 and return_train_score=True\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "# -------------------------------\n",
    "print(clf1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_i1BM7zQcWvw"
   },
   "outputs": [],
   "source": [
    "# XXX\n",
    "# TODO: Calculate the training and test set accuracy values after hyperparameter tuning and standardization. \n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "y_train_pred = clf1.predict(x_train_std)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "y_test_pred = clf1.predict(x_test_std)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_UzWph6Y9rLs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9797254150702427\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy (on the training set) using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "print(train_accuracy)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gSQXwaDn9rLw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9778398510242086\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Test its accuracy (on the test set) using the accuracy_score method.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "print(test_accuracy)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Io4IVbup9rL1"
   },
   "source": [
    "## Q3.4.4 Cross Validation Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1kVfAqsbcWv1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 6 3 4 1 2]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get the rank test score for all hyperparameter values that you obtained in Q3.4.3. The \n",
    "# GridSearchCV class holds a  ‘cv_results_’ dictionary that should help you report these metrics easily.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "\n",
    "print(clf1.cv_results_['rank_test_score']) \n",
    "\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2UrUu1DXcWv2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97637292 0.97070562 0.97900702 0.97812899 0.97948595 0.97916667]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get the mean testing score for all of hyperparameter values that you obtained in Q3.4.3. The \n",
    "# GridSearchCV class holds a  ‘cv_results_’ dictionary that should help you report these metrics easily.\n",
    "# XXX\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "print(clf1.cv_results_['mean_test_score'])\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c2qDYMjgcWv5"
   },
   "source": [
    "# Q3.5 PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-C9BuGsqcWv5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=8, random_state=None,\n",
       "  svd_solver='full', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Perform dimensionality reduction of the data using PCA.\n",
    "#       Set parameters n_component to 8 and svd_solver to 'full'. Keep other parameters at their default value.\n",
    "# XXX\n",
    "\n",
    "# NOTE: Use the full x data set for this section 'x_data'\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# You should see an output here of PCA(copy=True....)\n",
    "pca = PCA(n_components=8, svd_solver='full')\n",
    "pca.fit(x_data)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CZCJCtGhcWv7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.71053041e-01 7.81934383e-02 4.11562290e-02 6.15967691e-03\n",
      " 2.43717952e-03 9.58578490e-04 3.90570992e-05 2.79968662e-06]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get percentage of variance explained by each of the selected components\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "print(pca.explained_variance_ratio_)\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9nPDDyTcWv8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14430.28004546  4323.5214088   3136.68022725  1213.47665361\n",
      "   763.30168073   478.70316467    96.62788002    25.87063984]\n"
     ]
    }
   ],
   "source": [
    "# XXX\n",
    "# TODO: Get the singular values corresponding to each of the selected components.\n",
    "# XXX\n",
    "\n",
    "# -------------------------------\n",
    "# ADD CODE HERE\n",
    "# Requires a print() statement\n",
    "print(pca.singular_values_)\n",
    "# -------------------------------"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "hw4q3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
